1. What ChatGPT is

```
ChatGPT and GPT-4 are artificial intelligence (AI) chatbots or large language models built by [OpenAIExternal link](https://openai.com/), which allow people to interact in a conversational way. They use natural language processing (NLP) to generate conversations and respond with relevant answers that mimic human speech

GPT stands for ‘Generative Pre-trained Transformer’, which refers to how these bots process requests and formulate responses.

ChatGPT and GPT-4 are also available as APIs or application programming interfaces that can be integrated into other apps and online services.

https://www.esafety.gov.au/key-topics/esafety-guide/chatgpt-and-gpt-4
```

```
Artificial intelligence (AI) refers to an engineered system that generates
predictive outputs such as content, forecasts, recommendations, or decisions
for a given set of human-defined objectives or parameters without explicit
programming. AI systems are designed to operate with varying levels of
automation.
Machine learning are the patterns derived from training data using machine
learning algorithms, which can be applied to new data for prediction or
decision-making purposes.

Generative AI models produce novel content such as text, images, audio, video
and code in response to prompts.
A large language model (LLM) is a type of generative AI that specialises in the
generation of human-like text.
Multimodal Foundation Model (MfM) is a type of generative AI that can
process and output multiple data types (e.g. text, images, audio)

https://www.esafety.gov.au/sites/default/files/2023-08/Generative%20AI%20-%20Position%20Statement%20-%20August%202023%20.pdf
```

```
AI is a branch of computer science that focuses on creating
intelligent machines that can think and act like humans. AI
systems are designed to learn from their environment and
make decisions based on the data they receive. AI can be used
to solve complex problems, such as medical diagnosis,
autonomous vehicles, and natural language processing.


There are several types of AI, including machine learning,
deep learning, and natural language processing. Machine
learning is a type of AI that uses algorithms to learn from data
and make predictions. Deep learning is a type of machine
learning that uses neural networks [4] to process data. Natural
language processing (NLP) is a type of AI that uses
algorithms to understand and generate human-like
conversations

ChatGPT is a natural language processing (NLP) system developed by Open AI

Deng, J. and Lin, Y., 2022. The benefits and challenges of ChatGPT: An overview. _Frontiers in Computing and Intelligent Systems_, _2_(2), pp.81-83.
```

![](docs/Images/Pasted%20image%2020231026034402.png)


2. What it does
   
```
Both ChatGPT and GPT-4 can chat with you, answer follow-up questions, challenge incorrect information and perform tasks such as writing text and generating code and other outputs.

ChatGPT can only provide answers based on the information it has been trained with and does not have the ability to search the internet for new information. However, GPT-4 (the latest language model from OpenAI) can be connected to the internet via plugins, giving it the power to search for information and datasets online

ChatGPT and GPT-4 are used for: content sharing, encrypted, gaming, in-app purchasing, location sharing, messaging/online chat, screen capture and voice chat.

https://www.esafety.gov.au/key-topics/esafety-guide/chatgpt-and-gpt-4
```


```
It is designed to generate human-like conversations by understanding the context of a conversation and generating appropriate responses

It is able to understand the context of a conversation and generate appropriate responses. It can also generate responses in multiple languages, including English, Spanish, French, and German. Additionally, ChatGPT is able to generate responses in different styles, such as formal, informal, and humorous.

Deng, J. and Lin, Y., 2022. The benefits and challenges of ChatGPT: An overview. _Frontiers in Computing and Intelligent Systems_, _2_(2), pp.81-83.
```
   
3. A short history of large language models
   
```
1. **Early Beginnings**:  
- "The research in this field can be traced back decades ago. We can mark the beginning of research in the field of generative AI in the 1960s, when Joseph Weizenbaum developed the chatbot ELIZA, one of the first examples of an NLP system."
  
2. **Challenges and ANNs**:   
- "However, we know that modern generative AI is a subfield of DL and, although the first Artificial Neural Networks (ANNs) were first introduced in the 1940s, researchers faced several challenges, including limited computing power and a lack of understanding of the biological basis of the brain."
  
3. **Backpropagation and Training**:
- "By the 1980s... the advent of the backpropagation algorithm facilitated the training phase of ANNs. Indeed, before the advent of backpropagation, training Neural Networks was difficult because it was not possible to efficiently calculate the gradient of the error with respect to the parameters or weights associated with each neuron, while backpropagation made it possible to automate the training process and enabled the application of ANNs."
  
4. **Generative Models - VAEs**:  
- "In 2013, Kingma and Welling introduced a new model architecture in their paper Auto-Encoding Variational Bayes, called Variational Autoencoders (VAEs). VAEs are generative models that are based on the concept of variational inference... The key innovation of VAEs is the introduction of a probabilistic interpretation of the latent space."
  
5. **Introduction of GANs**:  
- "Only 1 year later, GANs were introduced by Ian Goodfellow... During training, the generator tries to create data that can fool the discriminator into thinking it’s real, while the discriminator tries to become better at distinguishing between real and fake data."
  
6. **Transformers and Large Language Models**:   
- "Another great milestone was achieved in 2017 when a new architecture, called Transformer, was introduced by Google researchers... Transformers were indeed the foundations for massive language models called Bidirectional Encoder Representations from Transformers (BERT), introduced by Google in 2018, and they soon become the baseline in NLP experiments. Transformers are also the foundations of all the Generative Pre-Trained (GPT) models introduced by OpenAI, including GPT-3, the model behind ChatGPT."
  
7. **Generative AI Going Mainstream**:
- "Not by chance, 2022 has been dubbed the year of generative AI. This was the year when powerful AI models and tools became widespread among the general public... Once generative AI models have been widespread to the public, every individual user or organization had the possibility to experiment with and appreciate its potential, even without being a data scientist or ML engineer."

GPT-3: A set of models that can understand and generate natural language. GPT-3 has been trained on a large corpus of text and can perform a wide range of natural language tasks such as language translation, summarization, question-answering, and more. Here is an example:

GPT-3.5: This is a newer set of models that build upon GPT-3 and aim to improve its natural language understanding and generation abilities. GPT-3.5 models can perform complex natural language tasks such as composing coherent paragraphs or essays, generating poetry, and even creating computer programs in natural language. GPT-3.5 is the model behind ChatGPT and, on top of its API, it is also consumable within the Playground with a dedicated UI:

Valentina Alto - Modern Generative AI with ChatGPT
```
   
4. How ChatGPT was trained and where that data came from
   
```
Both models have been trained with huge amounts of data and use human feedback and reward models to rank the best responses.

ChatGPT is based on a deep learning model called GPT-3, which is trained on a large dataset of conversations.

https://www.esafety.gov.au/key-topics/esafety-guide/chatgpt-and-gpt-4
```

```
For example, a language model such as GPT-3, developed by OpenAI, can be trained on large amounts of text data and then used to generate new, coherent, and grammatically correct text in different languages (both in terms of input and output), as well as extracting relevant features from text such as keywords, topics, or full summaries.

Valentina Alto - Modern Generative AI with ChatGPT
```

```
We trained this model using Reinforcement Learning from Human Feedback (RLHF), using the same methods as InstructGPT, but with slight differences in the data collection setup. We trained an initial model using supervised fine-tuning: human AI trainers provided conversations in which they played both sides—the user and an AI assistant. We gave the trainers access to model-written suggestions to help them compose their responses. We mixed this new dialogue dataset with the InstructGPT dataset, which we transformed into a dialogue format.

To create a reward model for reinforcement learning, we needed to collect comparison data, which consisted of two or more model responses ranked by quality. To collect this data, we took conversations that AI trainers had with the chatbot. We randomly selected a model-written message, sampled several alternative completions, and had AI trainers rank them. Using these reward models, we can fine-tune the model using Proximal Policy Optimization. We performed several iterations of this process.

ChatGPT is fine-tuned from a model in the GPT-3.5 series, which finished training in early 2022. You can learn more about the 3.5 series [here](https://beta.openai.com/docs/model-index-for-researchers). ChatGPT and GPT-3.5 were trained on an Azure AI supercomputing infrastructure.

https://openai.com/blog/chatgpt
```

![](docs/Images/ChatGPT_Diagram.svg)

```
Pre-training Approach:
"Our basic pre-training approach, including model, data, and training, is similar to the process described in [RWC+19 ], with relatively straightforward scaling up of the model size, dataset size and diversity, and length of training."

Learning Within the Context:
"Our use of in-context learning is also similar to [RWC+19], but in this work we systematically explore different settings for learning within the context."

Different Training Settings:
"Specifically, we can identify at least four points on this spectrum: Fine-Tuning (FT), Few-Shot (FS), One-Shot (1S), and Zero-Shot (0S)."

Model and Architecture:
"We use the same model and architecture as GPT-2 [ RWC+19 ], including the modified initialization, pre-normalization, and reversible tokenization described therein, with the exception that we use alternating dense and locally banded sparse attention patterns in the layers of the transformer, similar to the Sparse Transformer [ CGRS19 ]."

Training Dataset:
"Datasets for language models have rapidly expanded, culminating in the Common Crawl dataset2 [RSR+19 ] constituting nearly a trillion words."
"However, we have found that unfiltered or lightly filtered versions of Common Crawl tend to have lower quality than more curated datasets. Therefore, we took 3 steps to improve the average quality of our datasets: (1) we downloaded and filtered a version of CommonCrawl based on similarity to a range of high-quality reference corpora, (2) we performed fuzzy deduplication at the document level, within and across datasets, to prevent redundancy and preserve the integrity of our held-out validation set as an accurate measure of overfitting, and (3) we also added known high-quality reference corpora to the training mix to augment CommonCrawl and increase its diversity."
"For the third, we added several curated high-quality datasets, including an expanded version of the WebText dataset [ RWC+19], collected by scraping links over a longer period of time, and first described in [KMH+20], two internet-based books corpora (Books1 and Books2) and English-language Wikipedia."

Concerns about Data Contamination:
"A major methodological concern with language models pretrained on a broad swath of internet data, particularly large models with the capacity to memorize vast amounts of content, is potential contamination of downstream tasks by having their test or development sets inadvertently seen during pre-training."

Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A. and Agarwal, S., 2020. Language models are few-shot learners. _Advances in neural information processing systems_, _33_, pp.1877-1901.
```

5. How ChatGPT stores its interaction data
   

   
6. What any ethical issues are
   
```
ChatGPT and GPT-4 have certain limitations, as OpenAI makes clear, including sometimes writing answers that sound believable but are factually inaccurate, giving biased responses and the risk that they may action inappropriate or harmful requests.

https://www.esafety.gov.au/key-topics/esafety-guide/chatgpt-and-gpt-4
```

```
Biases & Limitations:
"Another limitation is that ChatGPT is trained on a large dataset of human language, and as a result it may produce responses that contain biased or offensive language."
"One major limitation is that it is only able to generate text based on the input provided to it, and it does not have access to external information or the ability to browse the internet."

Deng, J. and Lin, Y., 2022. The benefits and challenges of ChatGPT: An overview. _Frontiers in Computing and Intelligent Systems_, _2_(2), pp.81-83.
```
   
7. What any possible legal issues are
   
```
They may also infringe intellectual copyright by incorporating content without permission and not attributing content.

https://www.esafety.gov.au/key-topics/esafety-guide/chatgpt-and-gpt-4
```

```
Security Concerns:
"One major concern is the risk of adversarial attacks, in which an attacker attempts to manipulate the model by providing malicious inputs that cause it to produce incorrect or undesirable outputs."
"ChatGPT's ability to generate human-like text raises the risk of impersonation and identity theft."

Misinformation & Propaganda:
"Another concern is the potential for ChatGPT to be used to spread misinformation or propaganda, particularly if it is integrated into platforms that have a wide reach such as social media."

Deng, J. and Lin, Y., 2022. The benefits and challenges of ChatGPT: An overview. _Frontiers in Computing and Intelligent Systems_, _2_(2), pp.81-83.
```
   
8. A short set of guidelines for best practice when using ChatGPT

```
Manage your data
Outlines ways to manage your data, including turning off your chat history and choosing which conversations can be used to train AI models.

https://www.esafety.gov.au/key-topics/esafety-guide/chatgpt-and-gpt-4
```

```
- Data anonymisation: Replace or alter personal information in the text using information that cannot be linked to the individual.
- Data masking: Replace personal information in the text, such as email addresses or phone numbers, with fictional data that retains the same format.
- Include only relevant data: Choose only information that is relevant.

verify and edit AI generated content to ensure accuracy and suitability of the output

Writing a clear and effective prompt can greatly improve the quality of output from generative AI tools, while also reducing errors or irrelevant responses. Provide clear roles and examples when creating a prompt, which involves defining a character and role for the AI tool, giving a clear task, providing examples and additional guidelines, specifying the type of output required, and including any extra phrases to improve the prompt. These steps help the AI model understand the task more accurately and produce results that meet the required specifications.

https://education.nsw.gov.au/teaching-and-learning/education-for-a-changing-world/guidelines-regarding-use-of-generative-ai-chatgpt
```


```
To prevent hallucinations, some good practices should be kept in mind: 

• Be specific and clear: Make sure your prompt is well-defined and clearly states what you are looking to achieve. This will help the model generate more focused and relevant responses. A prompt such as Tell me about the world would probably not generate great results. 

• Provide sufficient context: The more context you can provide, the better the model will be able to understand what you are looking for and generate a response that is relevant to your needs. 

• Avoid ambiguity: Avoid using vague or ambiguous terms or phrases in your prompt, as this can make it difficult for the model to understand what you are looking for. 

• Use concise language: Keep your prompts as concise as possible, while still providing enough information for the model to generate a response. This will help ensure that the model generates focused and concise responses. 

• Be mindful of the training data: ChatGPT has been trained on a large corpus of text, and it may generate responses that are biased or inaccurate based on the patterns in that data. Be mindful of this and consider adjusting your prompts if you suspect that the model is generating responses that are not appropriate or accurate.

Valentina Alto - Modern Generative AI with ChatGPT
```