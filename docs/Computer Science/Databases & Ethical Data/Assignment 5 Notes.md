1. What ChatGPT is

```
ChatGPT and GPT-4 are artificial intelligence (AI) chatbots or large language models built by [OpenAIExternal link](https://openai.com/), which allow people to interact in a conversational way. They use natural language processing (NLP) to generate conversations and respond with relevant answers that mimic human speech

GPT stands for ‘Generative Pre-trained Transformer’, which refers to how these bots process requests and formulate responses.

ChatGPT and GPT-4 are also available as APIs or application programming interfaces that can be integrated into other apps and online services.

https://www.esafety.gov.au/key-topics/esafety-guide/chatgpt-and-gpt-4
```

```
Artificial intelligence (AI) refers to an engineered system that generates
predictive outputs such as content, forecasts, recommendations, or decisions
for a given set of human-defined objectives or parameters without explicit
programming. AI systems are designed to operate with varying levels of
automation.
Machine learning are the patterns derived from training data using machine
learning algorithms, which can be applied to new data for prediction or
decision-making purposes.

Generative AI models produce novel content such as text, images, audio, video
and code in response to prompts.
A large language model (LLM) is a type of generative AI that specialises in the
generation of human-like text.
Multimodal Foundation Model (MfM) is a type of generative AI that can
process and output multiple data types (e.g. text, images, audio)

https://www.esafety.gov.au/sites/default/files/2023-08/Generative%20AI%20-%20Position%20Statement%20-%20August%202023%20.pdf
```

```
AI is a branch of computer science that focuses on creating
intelligent machines that can think and act like humans. AI
systems are designed to learn from their environment and
make decisions based on the data they receive. AI can be used
to solve complex problems, such as medical diagnosis,
autonomous vehicles, and natural language processing.


There are several types of AI, including machine learning,
deep learning, and natural language processing. Machine
learning is a type of AI that uses algorithms to learn from data
and make predictions. Deep learning is a type of machine
learning that uses neural networks [4] to process data. Natural
language processing (NLP) is a type of AI that uses
algorithms to understand and generate human-like
conversations

ChatGPT is a natural language processing (NLP) system developed by Open AI

Deng, J. and Lin, Y., 2022. The benefits and challenges of ChatGPT: An overview. _Frontiers in Computing and Intelligent Systems_, _2_(2), pp.81-83.
```

![](docs/Images/Pasted%20image%2020231026034402.png)


2. What it does
   
```
Both ChatGPT and GPT-4 can chat with you, answer follow-up questions, challenge incorrect information and perform tasks such as writing text and generating code and other outputs.

ChatGPT can only provide answers based on the information it has been trained with and does not have the ability to search the internet for new information. However, GPT-4 (the latest language model from OpenAI) can be connected to the internet via plugins, giving it the power to search for information and datasets online

ChatGPT and GPT-4 are used for: content sharing, encrypted, gaming, in-app purchasing, location sharing, messaging/online chat, screen capture and voice chat.

https://www.esafety.gov.au/key-topics/esafety-guide/chatgpt-and-gpt-4
```


```
It is designed to generate human-like conversations by understanding the context of a conversation and generating appropriate responses

It is able to understand the context of a conversation and generate appropriate responses. It can also generate responses in multiple languages, including English, Spanish, French, and German. Additionally, ChatGPT is able to generate responses in different styles, such as formal, informal, and humorous.

Deng, J. and Lin, Y., 2022. The benefits and challenges of ChatGPT: An overview. _Frontiers in Computing and Intelligent Systems_, _2_(2), pp.81-83.
```
   
3. A short history of large language models
   
```
1. **Early Beginnings**:  
- "The research in this field can be traced back decades ago. We can mark the beginning of research in the field of generative AI in the 1960s, when Joseph Weizenbaum developed the chatbot ELIZA, one of the first examples of an NLP system."
  
2. **Challenges and ANNs**:   
- "However, we know that modern generative AI is a subfield of DL and, although the first Artificial Neural Networks (ANNs) were first introduced in the 1940s, researchers faced several challenges, including limited computing power and a lack of understanding of the biological basis of the brain."
  
3. **Backpropagation and Training**:
- "By the 1980s... the advent of the backpropagation algorithm facilitated the training phase of ANNs. Indeed, before the advent of backpropagation, training Neural Networks was difficult because it was not possible to efficiently calculate the gradient of the error with respect to the parameters or weights associated with each neuron, while backpropagation made it possible to automate the training process and enabled the application of ANNs."
  
4. **Generative Models - VAEs**:  
- "In 2013, Kingma and Welling introduced a new model architecture in their paper Auto-Encoding Variational Bayes, called Variational Autoencoders (VAEs). VAEs are generative models that are based on the concept of variational inference... The key innovation of VAEs is the introduction of a probabilistic interpretation of the latent space."
  
5. **Introduction of GANs**:  
- "Only 1 year later, GANs were introduced by Ian Goodfellow... During training, the generator tries to create data that can fool the discriminator into thinking it’s real, while the discriminator tries to become better at distinguishing between real and fake data."
  
6. **Transformers and Large Language Models**:   
- "Another great milestone was achieved in 2017 when a new architecture, called Transformer, was introduced by Google researchers... Transformers were indeed the foundations for massive language models called Bidirectional Encoder Representations from Transformers (BERT), introduced by Google in 2018, and they soon become the baseline in NLP experiments. Transformers are also the foundations of all the Generative Pre-Trained (GPT) models introduced by OpenAI, including GPT-3, the model behind ChatGPT."
  
7. **Generative AI Going Mainstream**:
- "Not by chance, 2022 has been dubbed the year of generative AI. This was the year when powerful AI models and tools became widespread among the general public... Once generative AI models have been widespread to the public, every individual user or organization had the possibility to experiment with and appreciate its potential, even without being a data scientist or ML engineer."

GPT-3: A set of models that can understand and generate natural language. GPT-3 has been trained on a large corpus of text and can perform a wide range of natural language tasks such as language translation, summarization, question-answering, and more. Here is an example:

GPT-3.5: This is a newer set of models that build upon GPT-3 and aim to improve its natural language understanding and generation abilities. GPT-3.5 models can perform complex natural language tasks such as composing coherent paragraphs or essays, generating poetry, and even creating computer programs in natural language. GPT-3.5 is the model behind ChatGPT and, on top of its API, it is also consumable within the Playground with a dedicated UI:

Valentina Alto - Modern Generative AI with ChatGPT
```
   
4. How ChatGPT was trained and where that data came from
   
```
Both models have been trained with huge amounts of data and use human feedback and reward models to rank the best responses.

ChatGPT is based on a deep learning model called GPT-3, which is trained on a large dataset of conversations.

https://www.esafety.gov.au/key-topics/esafety-guide/chatgpt-and-gpt-4
```

```
For example, a language model such as GPT-3, developed by OpenAI, can be trained on large amounts of text data and then used to generate new, coherent, and grammatically correct text in different languages (both in terms of input and output), as well as extracting relevant features from text such as keywords, topics, or full summaries.

Valentina Alto - Modern Generative AI with ChatGPT
```

```
We trained this model using Reinforcement Learning from Human Feedback (RLHF), using the same methods as InstructGPT, but with slight differences in the data collection setup. We trained an initial model using supervised fine-tuning: human AI trainers provided conversations in which they played both sides—the user and an AI assistant. We gave the trainers access to model-written suggestions to help them compose their responses. We mixed this new dialogue dataset with the InstructGPT dataset, which we transformed into a dialogue format.

To create a reward model for reinforcement learning, we needed to collect comparison data, which consisted of two or more model responses ranked by quality. To collect this data, we took conversations that AI trainers had with the chatbot. We randomly selected a model-written message, sampled several alternative completions, and had AI trainers rank them. Using these reward models, we can fine-tune the model using Proximal Policy Optimization. We performed several iterations of this process.

ChatGPT is fine-tuned from a model in the GPT-3.5 series, which finished training in early 2022. You can learn more about the 3.5 series [here](https://beta.openai.com/docs/model-index-for-researchers). ChatGPT and GPT-3.5 were trained on an Azure AI supercomputing infrastructure.

https://openai.com/blog/chatgpt
```

![](docs/Images/ChatGPT_Diagram.svg)

```
Pre-training Approach:
"Our basic pre-training approach, including model, data, and training, is similar to the process described in [RWC+19 ], with relatively straightforward scaling up of the model size, dataset size and diversity, and length of training."

Learning Within the Context:
"Our use of in-context learning is also similar to [RWC+19], but in this work we systematically explore different settings for learning within the context."

Different Training Settings:
"Specifically, we can identify at least four points on this spectrum: Fine-Tuning (FT), Few-Shot (FS), One-Shot (1S), and Zero-Shot (0S)."

Model and Architecture:
"We use the same model and architecture as GPT-2 [ RWC+19 ], including the modified initialization, pre-normalization, and reversible tokenization described therein, with the exception that we use alternating dense and locally banded sparse attention patterns in the layers of the transformer, similar to the Sparse Transformer [ CGRS19 ]."

Training Dataset:
"Datasets for language models have rapidly expanded, culminating in the Common Crawl dataset2 [RSR+19 ] constituting nearly a trillion words."
"However, we have found that unfiltered or lightly filtered versions of Common Crawl tend to have lower quality than more curated datasets. Therefore, we took 3 steps to improve the average quality of our datasets: (1) we downloaded and filtered a version of CommonCrawl based on similarity to a range of high-quality reference corpora, (2) we performed fuzzy deduplication at the document level, within and across datasets, to prevent redundancy and preserve the integrity of our held-out validation set as an accurate measure of overfitting, and (3) we also added known high-quality reference corpora to the training mix to augment CommonCrawl and increase its diversity."
"For the third, we added several curated high-quality datasets, including an expanded version of the WebText dataset [ RWC+19], collected by scraping links over a longer period of time, and first described in [KMH+20], two internet-based books corpora (Books1 and Books2) and English-language Wikipedia."

Concerns about Data Contamination:
"A major methodological concern with language models pretrained on a broad swath of internet data, particularly large models with the capacity to memorize vast amounts of content, is potential contamination of downstream tasks by having their test or development sets inadvertently seen during pre-training."

Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A. and Agarwal, S., 2020. Language models are few-shot learners. _Advances in neural information processing systems_, _33_, pp.1877-1901.
```

```
## 300 billion words. How many are yours?

ChatGPT is underpinned by a large language model that requires massive amounts of data to function and improve. The more data the model is trained on, the better it gets at detecting patterns, anticipating what will come next and generating plausible text.

OpenAI, the company behind ChatGPT, fed the tool some [300 billion words](https://www.sciencefocus.com/future-technology/gpt-3/) systematically scraped from the internet: books, articles, websites and posts – including personal information obtained without consent.

If you’ve ever written a blog post or product review, or commented on an article online, there’s a good chance this information was consumed by ChatGPT.

## So why is that an issue?

The data collection used to train ChatGPT is problematic for several reasons.

First, none of us were asked whether OpenAI could use our data. This is a clear violation of privacy, especially when data are sensitive and can be used to identify us, our family members, or our location.

Even when data are publicly available their use can breach what we call [contextual integrity](https://digitalcommons.law.uw.edu/wlr/vol79/iss1/10/). This is a fundamental principle in legal discussions of privacy. It requires that individuals’ information is not revealed outside of the context in which it was originally produced.

Also, OpenAI offers no procedures for individuals to check whether the company stores their personal information, or to request it be deleted. This is a guaranteed right in accordance with the European General Data Protection Regulation ([GDPR](https://gdpr-info.eu/art-17-gdpr/)) – although it’s still under debate whether ChatGPT is compliant [with GDPR requirements](https://blog.avast.com/chatgpt-data-use-legal).

This “right to be forgotten” is particularly important in cases where the information is inaccurate or misleading, which seems to be a [regular occurrence](https://www.fastcompany.com/90833017/openai-chatgpt-accuracy-gpt-4) with ChatGPT.

Moreover, the scraped data ChatGPT was trained on can be proprietary or copyrighted. For instance, when I prompted it, the tool produced the first few passages from Joseph Heller’s book Catch-22 – a copyrighted text.

https://theconversation.com/chatgpt-is-a-data-privacy-nightmare-if-youve-ever-posted-online-you-ought-to-be-concerned-199283
```

5. How ChatGPT stores its interaction data
   
```
## 1. Personal information we collect

We collect personal information relating to you (“Personal Information”) as follows:

**Personal Information You Provide**: We collect Personal Information if you create an account to use our Services or communicate with us as follows:

- _Account Information:_ When you create an account with us, we will collect information associated with your account, including your name, contact information, account credentials, payment card information, and transaction history, (collectively, “Account Information”).
- _User Content:_ When you use our Services, we collect Personal Information that is included in the input, file uploads, or feedback that you provide to our Services (“Content”). 
- _Communication Information_: If you communicate with us, we collect your name, contact information, and the contents of any messages you send (“Communication Information”).
- _Social Media Information_: We have pages on social media sites like Instagram, Facebook, Medium, Twitter, YouTube and LinkedIn. When you interact with our social media pages, we will collect Personal Information that you elect to provide to us, such as your contact details (collectively, “Social Information”). In addition, the companies that host our social media pages may provide us with aggregate information and analytics about our social media activity.

**Personal Information We Receive Automatically From Your Use of the Services**: When you visit, use, or interact with the Services, we receive the following information about your visit, use, or interactions (“Technical Information”):

- _Log Data_: Information that your browser automatically sends when you use our Services. Log data includes your Internet Protocol address, browser type and settings, the date and time of your request, and how you interact with our website.
- _Usage Data_: We may automatically collect information about your use of the Services, such as the types of content that you view or engage with, the features you use and the actions you take, as well as your time zone, country, the dates and times of access, user agent and version, type of computer or mobile device, and your computer connection.
- _Device Information_: Includes name of the device, operating system, device identifiers,  and browser you are using. Information collected may depend on the type of device you use and its settings.
- _Cookies_: We use cookies to operate and administer our Services, and improve your experience. A “cookie” is a piece of information sent to your browser by a website you visit. You can set your browser to accept all cookies, to reject all cookies, or to notify you whenever a cookie is offered so that you can decide each time whether to accept it. However, refusing a cookie may in some cases preclude you from using, or negatively affect the display or function of, a website or certain areas or features of a website. For more details on cookies, please visit [All About Cookies](https://allaboutcookies.org/).
- _Analytics_: We may use a variety of online analytics products that use cookies to help us analyze how users use our Services and enhance your experience when you use the Services.

## 2. How we use personal information

We may use Personal Information for the following purposes:

- To provide, administer, maintain and/or analyze the Services;
- To improve our Services and conduct research;
- To communicate with you;
- To develop new programs and services;
- To prevent fraud, criminal activity, or misuses of our Services, and to protect the security of our IT systems, architecture, and networks;
- To carry out business transfers; and
- To comply with legal obligations and legal process and to protect our rights, privacy, safety, or property, and/or that of our affiliates, you, or other third parties.

**Aggregated or De-Identified Information**. We may aggregate or de-identify Personal Information so that it may no longer be used to identify you and use such information to analyze the effectiveness of our Services, to improve and add features to our Services, to conduct research and for other similar purposes. In addition, from time to time, we may analyze the general behavior and characteristics of users of our Services and share aggregated information like general user statistics with third parties, publish such aggregated information or make such aggregated information generally available. We may collect aggregated information through the Services, through cookies, and through other means described in this Privacy Policy. We will maintain and use de-identified information in anonymous or de-identified form and we will not attempt to reidentify the information, unless required by law.

As noted above, we may use Content you provide us to improve our Services, for example to train the models that power ChatGPT. See [here](https://help.openai.com/en/articles/5722486-how-your-data-is-used-to-improve-model-performance) for instructions on how you can opt out of our use of your Content to train our models.
https://openai.com/policies/privacy-policy
```

```
Finally, OpenAI did not pay for the data it scraped from the internet. The individuals, website owners and companies that produced it were not compensated. This is particularly noteworthy considering OpenAI was recently [valued at US$29 billion](https://www.nasdaq.com/articles/microsofts-%2410-billion-investment-in-openai%3A-how-it-could-impact-the-ai-industry-and-stock), more than double its [value in 2021](https://www.forbes.com/sites/nicholasreimann/2023/01/05/chatgpt-creator-openai-discussing-offer-valuing-company-at-29-billion-report-says/?sh=f2ca73b11e04).

OpenAI has also just [announced ChatGPT Plus](https://openai.com/blog/chatgpt-plus/), a paid subscription plan that will offer customers ongoing access to the tool, faster response times and priority access to new features. This plan will contribute to expected [revenue of $1 billion by 2024](https://www.reuters.com/business/chatgpt-owner-openai-projects-1-billion-revenue-by-2024-sources-2022-12-15/).

None of this would have been possible without data – our data – collected and used without our permission.

## A flimsy privacy policy

Another privacy risk involves the data provided to ChatGPT in the form of user prompts. When we ask the tool to answer questions or perform tasks, we may inadvertently hand over [sensitive information](https://www.forbes.com/sites/lanceeliot/2023/01/27/generative-ai-chatgpt-can-disturbingly-gobble-up-your-private-and-confidential-data-forewarns-ai-ethics-and-ai-law/?sh=5d7dd7ce7fdb) and put it in the public domain.

For instance, an attorney may prompt the tool to review a draft divorce agreement, or a programmer may ask it to check a piece of code. The agreement and code, in addition to the outputted essays, are now part of ChatGPT’s database. This means they can be used to further train the tool, and be included in responses to other people’s prompts.

Beyond this, OpenAI gathers a broad scope of other user information. According to the company’s [privacy policy](https://openai.com/privacy/), it collects users’ IP address, browser type and settings, and data on users’ interactions with the site – including the type of content users engage with, features they use and actions they take.

It also collects information about users’ browsing activities over time and across websites. Alarmingly, OpenAI states it may [share users’ personal information](https://openai.com/privacy/) with unspecified third parties, without informing them, to meet their business objectives.

https://theconversation.com/chatgpt-is-a-data-privacy-nightmare-if-youve-ever-posted-online-you-ought-to-be-concerned-199283
```
   
6. What any ethical issues are
   
```
ChatGPT and GPT-4 have certain limitations, as OpenAI makes clear, including sometimes writing answers that sound believable but are factually inaccurate, giving biased responses and the risk that they may action inappropriate or harmful requests.

https://www.esafety.gov.au/key-topics/esafety-guide/chatgpt-and-gpt-4
```

```
Biases & Limitations:
"Another limitation is that ChatGPT is trained on a large dataset of human language, and as a result it may produce responses that contain biased or offensive language."
"One major limitation is that it is only able to generate text based on the input provided to it, and it does not have access to external information or the ability to browse the internet."

Deng, J. and Lin, Y., 2022. The benefits and challenges of ChatGPT: An overview. _Frontiers in Computing and Intelligent Systems_, _2_(2), pp.81-83.
```
   
7. What any possible legal issues are
   
```
They may also infringe intellectual copyright by incorporating content without permission and not attributing content.

https://www.esafety.gov.au/key-topics/esafety-guide/chatgpt-and-gpt-4
```

```
Security Concerns:
"One major concern is the risk of adversarial attacks, in which an attacker attempts to manipulate the model by providing malicious inputs that cause it to produce incorrect or undesirable outputs."
"ChatGPT's ability to generate human-like text raises the risk of impersonation and identity theft."

Misinformation & Propaganda:
"Another concern is the potential for ChatGPT to be used to spread misinformation or propaganda, particularly if it is integrated into platforms that have a wide reach such as social media."

Deng, J. and Lin, Y., 2022. The benefits and challenges of ChatGPT: An overview. _Frontiers in Computing and Intelligent Systems_, _2_(2), pp.81-83.
```
   
8. A short set of guidelines for best practice when using ChatGPT

```
Manage your data
Outlines ways to manage your data, including turning off your chat history and choosing which conversations can be used to train AI models.

https://www.esafety.gov.au/key-topics/esafety-guide/chatgpt-and-gpt-4
```

```
- Data anonymisation: Replace or alter personal information in the text using information that cannot be linked to the individual.
- Data masking: Replace personal information in the text, such as email addresses or phone numbers, with fictional data that retains the same format.
- Include only relevant data: Choose only information that is relevant.

verify and edit AI generated content to ensure accuracy and suitability of the output

Writing a clear and effective prompt can greatly improve the quality of output from generative AI tools, while also reducing errors or irrelevant responses. Provide clear roles and examples when creating a prompt, which involves defining a character and role for the AI tool, giving a clear task, providing examples and additional guidelines, specifying the type of output required, and including any extra phrases to improve the prompt. These steps help the AI model understand the task more accurately and produce results that meet the required specifications.

https://education.nsw.gov.au/teaching-and-learning/education-for-a-changing-world/guidelines-regarding-use-of-generative-ai-chatgpt
```


```
To prevent hallucinations, some good practices should be kept in mind: 

• Be specific and clear: Make sure your prompt is well-defined and clearly states what you are looking to achieve. This will help the model generate more focused and relevant responses. A prompt such as Tell me about the world would probably not generate great results. 

• Provide sufficient context: The more context you can provide, the better the model will be able to understand what you are looking for and generate a response that is relevant to your needs. 

• Avoid ambiguity: Avoid using vague or ambiguous terms or phrases in your prompt, as this can make it difficult for the model to understand what you are looking for. 

• Use concise language: Keep your prompts as concise as possible, while still providing enough information for the model to generate a response. This will help ensure that the model generates focused and concise responses. 

• Be mindful of the training data: ChatGPT has been trained on a large corpus of text, and it may generate responses that are biased or inaccurate based on the patterns in that data. Be mindful of this and consider adjusting your prompts if you suspect that the model is generating responses that are not appropriate or accurate.

Valentina Alto - Modern Generative AI with ChatGPT
```