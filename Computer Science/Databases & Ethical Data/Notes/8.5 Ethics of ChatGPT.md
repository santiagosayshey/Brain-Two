## Large Language Models

> *A large language model or LLM is a deep learning algorithm that can recognise summarise, translate, predict and generate text and other forms of content based on knowledge gained from massive data sets. Large language models are amongst the most successful applications of transformer models*

### Transformers
- Tokenise data
- Run mathematical and statistical formula across the data to discover relationships
- Look for patterns
- Use the self attention mechanism that allows it to associate context with the tokens
- **Internet trained models have internet scale biases**

### Where does this data come from?
- Internet data sources
- "Conversations"
- Human feedback 

### Issues under GDPR

![](Images/Pasted%20image%2020230912232928.png)

### Issues of Fact

![](Images/Pasted%20image%2020230912233101.png)

![](Images/Pasted%20image%2020230912233245.png)

##### Examples

```
You use github's copilot to write a piece of software, which is rather niche. The code you receive is heavily based on 1 sample as there aren't many to use, although it's been perturbed and altered. 

What are the ethical uses of this code? what are the conditions under which there is not ethical or legal use?
```




```
We define value neutrals being impartial and unbiased. In terms of the technology, it means that the technology is not intrinsically unethical or immoral, it's just that it can be put to that usage. 

Your design software that uses chat GPT to use a tweet as its basis and then build up a body of evidence, synthetically, that provides opposition to the opinion expressed in the tweet. The software constructs articles, tweets, identities, images and puts them all together to provide a cohesive referential thread. You argue that this is value neutral, as it's only the way people chose to use it that potentially causes problems. Discuss
``` 